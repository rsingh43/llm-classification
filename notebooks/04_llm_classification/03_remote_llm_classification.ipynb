{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661e93dd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dotenv\n",
    "import huggingface_hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "sys.path.append(\"../../src\")\n",
    "import dataframe_utils\n",
    "import huggingface_utils\n",
    "import GiveMeSomeCredit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d04b4d",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# MODEL_ID = \"mistralai/Mistral-7B-v0.1\"\n",
    "MODEL_ID = \"openai/gpt-oss-120b\"\n",
    "\n",
    "MODEL_URL = f\"https://huggingface.co/{MODEL_ID}\"\n",
    "print(f\"Model URL: {MODEL_URL}\")\n",
    "\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_ID}\"\n",
    "print(f\"API URL: {API_URL}\")\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "if HF_TOKEN is None:\n",
    "    raise RuntimeError(\"Please set HUGGINGFACEHUB_API_TOKEN in your environment variables.\")\n",
    "print(f\"Huggingface Token: {HF_TOKEN[:3]}...{HF_TOKEN[-4:]}\")\n",
    "\n",
    "TASK = \"conversational\"\n",
    "if not huggingface_utils.model_supports_task(MODEL_ID, TASK):\n",
    "    raise RuntimeError(f\"Model '{MODEL_ID}' does not support '{TASK}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION_COLUMN = (\"Input\", \"Description\")\n",
    "QUESTION_COLUMN = (\"Input\", \"Question\")\n",
    "FOLLOW_UP_COLUMN = (\"Input\", \"Question\")\n",
    "ANSWER_COLUMN = (MODEL_ID, \"LLM Answer\")\n",
    "REASONING_COLUMN = (MODEL_ID, \"LLM Reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb2ee",
   "metadata": {},
   "source": [
    "# Load the Dataset\n",
    "\n",
    "This section loads the validation data into a DataFrame and displays its basic information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2932162",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = GiveMeSomeCredit.load_dataframe(\n",
    "    \"classification_prompts.csv\", header=[0,1]\n",
    ").astype(\"string\")\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(\n",
    "        dataframe_utils.describe_df(classification_df)\n",
    "    )\n",
    "\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(\n",
    "        classification_df.head(5).style.set_properties(**{\"text-align\": \"left\"})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50428fc",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba52ed6",
   "metadata": {},
   "source": [
    "## `get_llm_classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e64580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt, model_id, token):\n",
    "    client = huggingface_hub.InferenceClient(model=model_id, token=token)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = client.chat_completion(messages=messages)\n",
    "    if response and response.choices and hasattr(response.choices[0], \"message\"):\n",
    "        return response.choices[0].message[\"content\"]\n",
    "    else:\n",
    "        raise ValueError(\"No valid content returned from model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7509d",
   "metadata": {},
   "source": [
    "## `get_batch_llm_classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_llm_responses(prompts, model_id, token):\n",
    "    results = list()\n",
    "    try:\n",
    "        for ii, prompt in enumerate(prompts):\n",
    "            result = get_llm_response(prompt, model_id=model_id, token=token)\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred after collecting {len(results)} results.\")\n",
    "        raise e\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfef7",
   "metadata": {},
   "source": [
    "## `chunked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b087a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked(iterable, n):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = list(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ffa9a",
   "metadata": {},
   "source": [
    "## `classify`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e483adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "def classify(\n",
    "    df, description_column, question_column, answer_column, model_id, token, batch_size=10\n",
    "):\n",
    "    missing_indices = df[df[answer_column].isna()].index.tolist()\n",
    "    total = len(missing_indices)\n",
    "    n_batches = int(np.ceil(total / batch_size))\n",
    "    print(f\"{total} samples\")\n",
    "    print(f\"{n_batches} batches of size {batch_size}\")\n",
    "    print(\"batch \", end=\" \")\n",
    "    \n",
    "    for ii,batch_indices in enumerate(chunked(missing_indices, batch_size)):\n",
    "        print(ii, end=\" \")\n",
    "        batch_df = df.loc[batch_indices]\n",
    "        prompt_series = batch_df[description_column] + \" \" + batch_df[question_column]\n",
    "        prompts = prompt_series.tolist()\n",
    "        results = get_batch_llm_responses(prompts, model_id=model_id, token=token)\n",
    "        df.loc[batch_indices, answer_column] = results\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cf80d",
   "metadata": {},
   "source": [
    "# Classify Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f248acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in (ANSWER_COLUMN, REASONING_COLUMN):\n",
    "    if column not in classification_df:\n",
    "        classification_df[column] = pd.Series(np.nan, dtype=\"string\")\n",
    "    \n",
    "classify(\n",
    "    df=classification_df,\n",
    "    description_column=DESCRIPTION_COLUMN,\n",
    "    question_column=QUESTION_COLUMN,\n",
    "    answer_column=ANSWER_COLUMN,\n",
    "    model_id=MODEL_ID,\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00208e",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916aded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(\n",
    "        classification_df.head(5).style.set_properties(**{\"text-align\": \"left\"})\n",
    "    )\n",
    "    \n",
    "GiveMeSomeCredit.save_dataframe(\n",
    "    classification_df, \"classification_prompts.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413fb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
